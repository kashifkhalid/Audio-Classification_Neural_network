{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import libraries# Import \n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import logfbank\n",
    "import pdb\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from pydub import AudioSegment\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import os, argparse\n",
    "import tensorflow as tf\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_files():\n",
    "    folder = 'C:/Users/kkhalid/project_kk/temp2/'\n",
    "    \n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "        except Exception as e:\n",
    "                print(e)\n",
    "    return           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename):\n",
    "    # We load the protobuf file from the disk and parse it to retrieve the \n",
    "    # unserialized graph_def\n",
    "    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "    # Then, we import the graph_def into a new Graph and returns it \n",
    "    with tf.Graph().as_default() as graph:\n",
    "        # The name var will prefix every op/nodes in your graph\n",
    "        # Since we load everything in a new graph, this is not needed\n",
    "        tf.import_graph_def(graph_def, name=\"prefix\")\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(file_name: str) -> tuple:\n",
    "    \n",
    "    folder = 'C:/Users/kkhalid/project_kk/temp2/'\n",
    "    \n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "        except Exception as e:\n",
    "                print(e)\n",
    "    filepath_finder=os.path.abspath(file_name)            \n",
    "    pathsp=filepath_finder.split('\\\\')\n",
    "    newfilename=pathsp[-1].split('.')\n",
    "    y, sr = librosa.load(filepath_finder)\n",
    "    dur=librosa.get_duration(y=y, sr=sr)\n",
    "    dur=dur/10\n",
    "    inc=0\n",
    "    for i in range(int(dur)):\n",
    "        \n",
    "        y, sr = librosa.load(file_name,offset=0.0+inc,duration=10.0)\n",
    "        librosa.output.write_wav('C:/Users/kkhalid/project_kk/temp2/'+newfilename[0]+str(inc)+'.wav',y,sr)\n",
    "        inc=inc+10\n",
    "        \n",
    "    return\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_name: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Extracts 193 chromatographic features from sound file. \n",
    "    including: MFCC's, Chroma_StFt, Melspectrogram, Spectral Contrast, and Tonnetz\n",
    "    NOTE: this extraction technique changes the time series nature of the data\n",
    "    \"\"\"\n",
    "    #inc=0\n",
    "    #y, sr = librosa.load(file_name)\n",
    "    #dur=librosa.get_duration(y=y, sr=sr)\n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "    return mfccs,chroma,mel,contrast,tonnetz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_time = timer()\n",
    "#a,b,c,d,e = extract_feature('C:/Users/kkhalid/project_kk/1980-oct27-3.wav')\n",
    "#end_time = timer()\n",
    "#print('time to extract features from one file: {:.3f}sec'.format((end_time-start_time)/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#argument_filename=sys.argv[1]\n",
    "#print(argument_filename)\n",
    "#print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter audio file path with format:1978-oct15-2\n",
      "1978-oct15-2.wav\n",
      "time taken: 2.0 minutes 38.8 seconds\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "start_time = timer()\n",
    "\n",
    "argument_filename=sys.argv[1]\n",
    "#print(argument_filename)\n",
    "#print(filepath)\n",
    "#argument_filename=input('enter audio file path with format:')\n",
    "#print(str(filepath))\n",
    "#pathsp=filepath.split('/')\n",
    "#newfilename=pathsp[-1].split('.')\n",
    "#print(newfilename[0])\n",
    "argument_filename=argument_filename+'.wav'\n",
    "print(argument_filename)\n",
    "trim(argument_filename)\n",
    "#pdb.set_trace()\n",
    "mfcc_data = []\n",
    "exception_count = 0\n",
    "loop_count=0\n",
    "inc=0\n",
    "\n",
    "mypath='C:/Users/kkhalid/project_kk/temp2/'\n",
    "files = [mypath + f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "len_files=len(files)\n",
    "\n",
    "for i in range(len_files):\n",
    "\n",
    "    mfccs,chroma,mel,contrast,tonnetz = extract_feature(files[i])\n",
    "    path,filename=os.path.split(files[i])\n",
    "\n",
    "    features = np.empty((0,193))\n",
    "    ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
    "    features = np.vstack([features,ext_features])\n",
    "    mfcc_data.append([filename,features])\n",
    "#pdb.set_trace()\n",
    "#print(features)\n",
    "end_time = timer()\n",
    "print(print(\"time taken: {0} minutes {1:.1f} seconds\".format((end_time - start_time)//60, (end_time - start_time)%60)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=[\"filename\",\"features\"]\n",
    "mfcc_pd=pd.DataFrame(data=mfcc_data,columns=cols)\n",
    "#mfcc_pd.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = [mfcc_pd['features'][i].ravel() for i in range(mfcc_pd.shape[0])]\n",
    "mfcc_pd['sample'] = pd.Series(ll, index=mfcc_pd.index)\n",
    "#del mfcc_pd['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working dataframe's shape: (60, 193)\n"
     ]
    }
   ],
   "source": [
    "s = list(mfcc_pd['sample'])\n",
    "\n",
    "s = pd.DataFrame(s)\n",
    "#print(s)\n",
    "\n",
    "data_cols = s.columns\n",
    "#s['filename'] = mfcc_pd['filename']\n",
    "print('working dataframe\\'s shape:', s.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=s[:]\n",
    "scaler1 = sk.preprocessing.StandardScaler().fit(test.loc[:,data_cols])\n",
    "test.loc[:,data_cols] = scaler1.transform(test.loc[:,data_cols])\n",
    "#print(test.loc[:,data_cols])\n",
    "#print(data_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.09053196e-16 8.94351038e-10 1.00000000e+00 9.96343785e-10]\n",
      " [3.05310183e-04 1.73168965e-02 9.80481207e-01 1.89654587e-03]\n",
      " [1.00954745e-09 2.59905192e-03 6.25685516e-06 9.97394681e-01]\n",
      " [3.39730740e-01 4.12565954e-02 4.06777114e-03 6.14944875e-01]\n",
      " [9.65303479e-06 1.31689742e-01 2.41573192e-02 8.44143271e-01]\n",
      " [9.86211002e-01 2.53167498e-04 3.52938969e-06 1.35323415e-02]\n",
      " [9.93169785e-01 2.48810451e-04 6.00966223e-06 6.57526497e-03]\n",
      " [9.99905109e-01 9.39944803e-05 5.97697947e-10 7.94334937e-07]\n",
      " [9.99960184e-01 5.35161337e-09 2.00199884e-06 3.77993456e-05]\n",
      " [8.47489595e-01 1.89909451e-02 7.42318080e-05 1.33445203e-01]\n",
      " [8.73142302e-01 1.76084843e-02 5.34423031e-02 5.58070205e-02]\n",
      " [5.45162335e-03 8.00819893e-04 2.61936197e-03 9.91128206e-01]\n",
      " [5.53432032e-02 4.84203128e-03 9.36051488e-01 3.76321282e-03]\n",
      " [1.82532496e-03 9.50226036e-04 1.77060370e-03 9.95453835e-01]\n",
      " [1.85578793e-01 1.36319280e-01 6.59931153e-02 6.12108886e-01]\n",
      " [9.83675778e-01 1.96287222e-03 8.55889084e-05 1.42757138e-02]\n",
      " [8.97905946e-01 1.57720540e-02 2.05165314e-04 8.61168802e-02]\n",
      " [2.60770181e-03 9.28687751e-01 5.33038019e-07 6.87039420e-02]\n",
      " [4.42833938e-02 8.87993455e-01 8.92601165e-05 6.76338971e-02]\n",
      " [8.99578094e-01 1.10608106e-02 3.93268710e-04 8.89678225e-02]\n",
      " [9.84441578e-01 1.07339760e-02 1.03448343e-03 3.79000697e-03]\n",
      " [8.74845207e-01 1.21143542e-01 2.80640074e-06 4.00843984e-03]\n",
      " [1.79852560e-01 8.20050478e-01 3.15932530e-10 9.69460234e-05]\n",
      " [7.49664068e-01 1.16202906e-01 1.34130090e-01 2.95222230e-06]\n",
      " [9.23546076e-01 7.61198029e-02 4.51330976e-07 3.33715929e-04]\n",
      " [2.15145146e-08 4.09143177e-05 1.82425799e-06 9.99957204e-01]\n",
      " [7.56694717e-05 5.35889342e-03 1.21424222e-04 9.94444072e-01]\n",
      " [1.25612405e-05 4.18349635e-03 5.74451825e-03 9.90059376e-01]\n",
      " [9.06134024e-03 1.85929981e-04 8.39146553e-04 9.89913583e-01]\n",
      " [7.62748837e-01 9.44991130e-03 2.51862337e-03 2.25282624e-01]\n",
      " [1.76384117e-06 2.35894040e-05 5.49508295e-05 9.99919653e-01]\n",
      " [4.71731164e-02 9.45827663e-01 3.10547242e-04 6.68861205e-03]\n",
      " [4.76613976e-02 5.95290260e-03 5.90318516e-02 8.87353897e-01]\n",
      " [7.92635083e-01 2.07230017e-01 5.99412533e-06 1.28872867e-04]\n",
      " [4.65497988e-06 1.01046944e-05 4.50904306e-04 9.99534369e-01]\n",
      " [2.51414869e-02 8.98895979e-01 2.38280481e-05 7.59388134e-02]\n",
      " [8.93894672e-01 1.02220417e-03 3.30239891e-05 1.05050087e-01]\n",
      " [9.99986291e-01 1.20437835e-05 6.91705970e-10 1.67906740e-06]\n",
      " [1.78349949e-03 9.44123805e-01 1.98039030e-10 5.40926866e-02]\n",
      " [9.56034064e-01 3.36582214e-02 2.01976382e-05 1.02875624e-02]\n",
      " [7.05413163e-01 1.10686757e-03 1.29269072e-04 2.93350697e-01]\n",
      " [3.60705644e-06 1.66466124e-02 6.55384247e-06 9.83343244e-01]\n",
      " [9.85615730e-01 5.94469486e-03 1.53061028e-05 8.42434540e-03]\n",
      " [9.97054100e-01 5.82102439e-05 8.32819933e-06 2.87928130e-03]\n",
      " [9.93662477e-01 1.38047952e-04 1.76764152e-04 6.02272479e-03]\n",
      " [6.22136635e-04 9.14634857e-03 1.30712435e-01 8.59519064e-01]\n",
      " [9.83638644e-01 1.24102235e-06 2.83762258e-08 1.63601227e-02]\n",
      " [9.98175502e-01 1.14790013e-03 8.29414546e-08 6.76477386e-04]\n",
      " [4.31487322e-01 5.15101070e-04 7.14933849e-05 5.67926109e-01]\n",
      " [9.96038914e-01 3.83396260e-03 2.07643069e-07 1.26752275e-04]\n",
      " [9.99998808e-01 1.02908768e-06 1.75469306e-09 7.86990455e-08]\n",
      " [9.99996781e-01 2.29748957e-06 3.89650712e-09 9.11763721e-07]\n",
      " [2.64624859e-18 1.00000000e+00 2.37801388e-20 2.95018801e-08]\n",
      " [1.06190382e-04 9.93854523e-01 2.06923418e-04 5.83233964e-03]\n",
      " [6.35558646e-03 9.93586242e-01 2.51601984e-09 5.81726563e-05]\n",
      " [3.42380808e-05 8.21066558e-01 1.00660980e-01 7.82382265e-02]\n",
      " [6.87802851e-01 1.70678169e-01 9.84331346e-05 1.41420454e-01]\n",
      " [1.42233050e-03 2.28278004e-04 4.78852271e-05 9.98301506e-01]\n",
      " [1.32866226e-05 5.03128802e-04 9.53570127e-01 4.59134802e-02]\n",
      " [5.24373201e-04 4.14601353e-04 5.85271046e-03 9.93208349e-01]]\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "#loading frozen model\n",
    "\n",
    "    # We use our \"load_graph\" function\n",
    "graph = load_graph('C:/Users/kkhalid/frozen_model.pb')\n",
    "\n",
    "#for op in graph.get_operations():\n",
    "    #print(op.name)\n",
    "    \n",
    "x = graph.get_tensor_by_name('prefix/input_data:0')\n",
    "y = graph.get_tensor_by_name('prefix/op_to_restore:0')  \n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    check_size=3000\n",
    "    feed_dict={x : test.loc[0:check_size-1,data_cols]}\n",
    "    y_out = sess.run(y, feed_dict)\n",
    "    print(y_out)\n",
    "    print(len(y_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading saved models\n",
    "def saved_model(model_name,data):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        new_saver = tf.train.import_meta_graph('CNN_model_trained.meta')\n",
    "        new_saver.restore(sess, tf.train.latest_checkpoint('./'))\n",
    "        #for op in graph.get_operations():\n",
    "         #   print(op.name)\n",
    "        \n",
    "        graph = tf.get_default_graph()\n",
    "        #op = sess.graph.get_operations()\n",
    "        #[m.values() for m in op][:]\n",
    "        input_data= graph.get_tensor_by_name(\"input_data:0\")\n",
    "        #data = tf.placeholder(tf.float32, shape=[None, 193])\n",
    "        check_size=3000\n",
    "        out = graph.get_tensor_by_name(\"op_to_restore:0\")\n",
    "        feed_dict={input_data : test.loc[0:check_size-1,data_cols]}\n",
    "        y_out = sess.run(out, feed_dict)\n",
    "\n",
    "    print(len(y_out))\n",
    "    print(y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "607.8055328798185\n",
      "['silence', 'silence', 'speech', 'speech', 'speech', 'music', 'music', 'music', 'music', 'music', 'music', 'speech', 'silence', 'speech', 'speech', 'music', 'music', 'noise', 'noise', 'music', 'music', 'music', 'noise', 'music', 'music', 'speech', 'speech', 'speech', 'speech', 'music', 'speech', 'noise', 'speech', 'music', 'speech', 'noise', 'music', 'music', 'noise', 'music', 'music', 'speech', 'music', 'music', 'music', 'speech', 'music', 'music', 'speech', 'music', 'music', 'music', 'noise', 'noise', 'noise', 'noise', 'music', 'speech', 'silence', 'speech']\n",
      "[[0, 10], [10, 20], [20, 30], [30, 40], [40, 50], [50, 60], [60, 70], [70, 80], [80, 90], [90, 100], [100, 110], [110, 120], [120, 130], [130, 140], [140, 150], [150, 160], [160, 170], [170, 180], [180, 190], [190, 200], [200, 210], [210, 220], [220, 230], [230, 240], [240, 250], [250, 260], [260, 270], [270, 280], [280, 290], [290, 300], [300, 310], [310, 320], [320, 330], [330, 340], [340, 350], [350, 360], [360, 370], [370, 380], [380, 390], [390, 400], [400, 410], [410, 420], [420, 430], [430, 440], [440, 450], [450, 460], [460, 470], [470, 480], [480, 490], [490, 500], [500, 510], [510, 520], [520, 530], [530, 540], [540, 550], [550, 560], [560, 570], [570, 580], [580, 590], [590, 600]]\n"
     ]
    }
   ],
   "source": [
    "filepath_finder=os.path.abspath(argument_filename)            \n",
    "X, sample_rate = librosa.load(filepath_finder)\n",
    "dur=librosa.get_duration(y=X, sr=sample_rate)\n",
    "#xaxis=np.empty()\n",
    "durations=[]\n",
    "#plt.figure()\n",
    "count=0\n",
    "inc=0\n",
    "time=[]\n",
    "tag=[]\n",
    "for out in range(len(y_out)):\n",
    "        while count <= dur:\n",
    "            begin=count\n",
    "            count=count+10\n",
    "            end=count\n",
    "            durations.append([begin,end])\n",
    "            #xaxis=sum(durations,[])\n",
    "            xaxis=durations\n",
    "        pred=y_out[out]\n",
    "        max_argu=np.argmax(pred)\n",
    "        \n",
    "        #for a in range(len(pred)):\n",
    "            #value=np.argmax(pred)\n",
    "        if max_argu==0:\n",
    "                time_instant=xaxis[inc]\n",
    "                classification='music'\n",
    "                time.append([time_instant])\n",
    "                tag.append([classification])\n",
    "                #print(xaxis[inc])\n",
    "                #print('music')\n",
    "        elif max_argu==1:\n",
    "            time_instant=xaxis[inc]\n",
    "            classification='noise'\n",
    "            time.append([time_instant])\n",
    "            tag.append([classification])\n",
    "            #print(xaxis[inc])\n",
    "            #print('noise')\n",
    "        elif max_argu==2:\n",
    "                time_instant=xaxis[inc]\n",
    "                classification='silence'\n",
    "                time.append([time_instant])\n",
    "                tag.append([classification])\n",
    "                #print(xaxis[inc])\n",
    "                #print('silence')\n",
    "        else:\n",
    "                time_instant=xaxis[inc]\n",
    "                classification='speech'\n",
    "                time.append([time_instant])\n",
    "                tag.append([classification])\n",
    "                #print(xaxis[inc])\n",
    "                #print('speech')\n",
    "        #xaxis.append([xvalue])  \n",
    "        inc=inc+1\n",
    "            \n",
    "print(dur)\n",
    "time=sum(time,[])\n",
    "tag=sum(tag,[])\n",
    "print(tag)\n",
    "print(time)\n",
    "#dur=int(dur)\n",
    "#dur=np.linspace(0,dur,len(y_out))\n",
    "#result=sum(xaxis,[])\n",
    "#print(np.array(result))\n",
    "#plt.figure(1)\n",
    "#plt.plot(dur,result)\n",
    "#plt.xlabel('audio length in seconds')\n",
    "#plt.ylabel('class')\n",
    "#plt.figure(2)\n",
    "#librosa.display.waveplot(X, sr=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'silence', 'end': 10, 'begin': 0}\n",
      "{'label': 'silence', 'end': 20, 'begin': 10}\n",
      "{'label': 'speech', 'end': 30, 'begin': 20}\n",
      "{'label': 'speech', 'end': 40, 'begin': 30}\n",
      "{'label': 'speech', 'end': 50, 'begin': 40}\n",
      "{'label': 'music', 'end': 60, 'begin': 50}\n",
      "{'label': 'music', 'end': 70, 'begin': 60}\n",
      "{'label': 'music', 'end': 80, 'begin': 70}\n",
      "{'label': 'music', 'end': 90, 'begin': 80}\n",
      "{'label': 'music', 'end': 100, 'begin': 90}\n",
      "{'label': 'music', 'end': 110, 'begin': 100}\n",
      "{'label': 'speech', 'end': 120, 'begin': 110}\n",
      "{'label': 'silence', 'end': 130, 'begin': 120}\n",
      "{'label': 'speech', 'end': 140, 'begin': 130}\n",
      "{'label': 'speech', 'end': 150, 'begin': 140}\n",
      "{'label': 'music', 'end': 160, 'begin': 150}\n",
      "{'label': 'music', 'end': 170, 'begin': 160}\n",
      "{'label': 'noise', 'end': 180, 'begin': 170}\n",
      "{'label': 'noise', 'end': 190, 'begin': 180}\n",
      "{'label': 'music', 'end': 200, 'begin': 190}\n",
      "{'label': 'music', 'end': 210, 'begin': 200}\n",
      "{'label': 'music', 'end': 220, 'begin': 210}\n",
      "{'label': 'noise', 'end': 230, 'begin': 220}\n",
      "{'label': 'music', 'end': 240, 'begin': 230}\n",
      "{'label': 'music', 'end': 250, 'begin': 240}\n",
      "{'label': 'speech', 'end': 260, 'begin': 250}\n",
      "{'label': 'speech', 'end': 270, 'begin': 260}\n",
      "{'label': 'speech', 'end': 280, 'begin': 270}\n",
      "{'label': 'speech', 'end': 290, 'begin': 280}\n",
      "{'label': 'music', 'end': 300, 'begin': 290}\n",
      "{'label': 'speech', 'end': 310, 'begin': 300}\n",
      "{'label': 'noise', 'end': 320, 'begin': 310}\n",
      "{'label': 'speech', 'end': 330, 'begin': 320}\n",
      "{'label': 'music', 'end': 340, 'begin': 330}\n",
      "{'label': 'speech', 'end': 350, 'begin': 340}\n",
      "{'label': 'noise', 'end': 360, 'begin': 350}\n",
      "{'label': 'music', 'end': 370, 'begin': 360}\n",
      "{'label': 'music', 'end': 380, 'begin': 370}\n",
      "{'label': 'noise', 'end': 390, 'begin': 380}\n",
      "{'label': 'music', 'end': 400, 'begin': 390}\n",
      "{'label': 'music', 'end': 410, 'begin': 400}\n",
      "{'label': 'speech', 'end': 420, 'begin': 410}\n",
      "{'label': 'music', 'end': 430, 'begin': 420}\n",
      "{'label': 'music', 'end': 440, 'begin': 430}\n",
      "{'label': 'music', 'end': 450, 'begin': 440}\n",
      "{'label': 'speech', 'end': 460, 'begin': 450}\n",
      "{'label': 'music', 'end': 470, 'begin': 460}\n",
      "{'label': 'music', 'end': 480, 'begin': 470}\n",
      "{'label': 'speech', 'end': 490, 'begin': 480}\n",
      "{'label': 'music', 'end': 500, 'begin': 490}\n",
      "{'label': 'music', 'end': 510, 'begin': 500}\n",
      "{'label': 'music', 'end': 520, 'begin': 510}\n",
      "{'label': 'noise', 'end': 530, 'begin': 520}\n",
      "{'label': 'noise', 'end': 540, 'begin': 530}\n",
      "{'label': 'noise', 'end': 550, 'begin': 540}\n",
      "{'label': 'noise', 'end': 560, 'begin': 550}\n",
      "{'label': 'music', 'end': 570, 'begin': 560}\n",
      "{'label': 'speech', 'end': 580, 'begin': 570}\n",
      "{'label': 'silence', 'end': 590, 'begin': 580}\n",
      "{'label': 'speech', 'end': 600, 'begin': 590}\n"
     ]
    }
   ],
   "source": [
    "#final=sum(final_results,[])\n",
    "#json_data=json.dumps(final)\n",
    "#print(json_data)\n",
    "#print(final[:])\n",
    "#type(json_data)\n",
    "my_dict={}\n",
    "json_string=\"\"\n",
    "i=0\n",
    "for i in range (len(tag)):\n",
    "    \n",
    "    my_dict[i]={'label':tag[i],'end':time[i][1],'begin':time[i][0]}\n",
    "\n",
    "    #json_data=json.dumps(my_dict[i],indent=4)\n",
    "    #json_string+=str(json_data)\n",
    "    #json_data=json.loads(json_data)\n",
    "    print(my_dict[i])\n",
    "    #print(json_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"label\": \"silence\",\n",
      "    \"end\": 20,\n",
      "    \"begin\": 0\n",
      "}\n",
      "{\n",
      "    \"label\": \"speech\",\n",
      "    \"end\": 50,\n",
      "    \"begin\": 20\n",
      "}\n",
      "{\n",
      "    \"label\": \"music\",\n",
      "    \"end\": 110,\n",
      "    \"begin\": 50\n",
      "}\n",
      "{\n",
      "    \"label\": \"speech\",\n",
      "    \"end\": 120,\n",
      "    \"begin\": 110\n",
      "}\n",
      "{\n",
      "    \"label\": \"silence\",\n",
      "    \"end\": 130,\n",
      "    \"begin\": 120\n",
      "}\n",
      "{\n",
      "    \"label\": \"speech\",\n",
      "    \"end\": 150,\n",
      "    \"begin\": 130\n",
      "}\n",
      "{\n",
      "    \"label\": \"music\",\n",
      "    \"end\": 170,\n",
      "    \"begin\": 150\n",
      "}\n",
      "{\n",
      "    \"label\": \"noise\",\n",
      "    \"end\": 190,\n",
      "    \"begin\": 170\n",
      "}\n",
      "{\n",
      "    \"label\": \"music\",\n",
      "    \"end\": 220,\n",
      "    \"begin\": 190\n",
      "}\n",
      "{\n",
      "    \"label\": \"noise\",\n",
      "    \"end\": 230,\n",
      "    \"begin\": 220\n",
      "}\n",
      "{\n",
      "    \"label\": \"music\",\n",
      "    \"end\": 250,\n",
      "    \"begin\": 230\n",
      "}\n",
      "{\n",
      "    \"label\": \"speech\",\n",
      "    \"end\": 290,\n",
      "    \"begin\": 250\n",
      "}\n",
      "{\n",
      "    \"label\": \"music\",\n",
      "    \"end\": 300,\n",
      "    \"begin\": 290\n",
      "}\n",
      "{\n",
      "    \"label\": \"speech\",\n",
      "    \"end\": 310,\n",
      "    \"begin\": 300\n",
      "}\n",
      "{\n",
      "    \"label\": \"noise\",\n",
      "    \"end\": 320,\n",
      "    \"begin\": 310\n",
      "}\n",
      "{\n",
      "    \"label\": \"speech\",\n",
      "    \"end\": 330,\n",
      "    \"begin\": 320\n",
      "}\n",
      "{\n",
      "    \"label\": \"music\",\n",
      "    \"end\": 340,\n",
      "    \"begin\": 330\n",
      "}\n",
      "{\n",
      "    \"label\": \"speech\",\n",
      "    \"end\": 350,\n",
      "    \"begin\": 340\n",
      "}\n",
      "{\n",
      "    \"label\": \"noise\",\n",
      "    \"end\": 360,\n",
      "    \"begin\": 350\n",
      "}\n",
      "{\n",
      "    \"label\": \"music\",\n",
      "    \"end\": 380,\n",
      "    \"begin\": 360\n",
      "}\n",
      "{\n",
      "    \"label\": \"noise\",\n",
      "    \"end\": 390,\n",
      "    \"begin\": 380\n",
      "}\n",
      "{\n",
      "    \"label\": \"music\",\n",
      "    \"end\": 410,\n",
      "    \"begin\": 390\n",
      "}\n",
      "{\n",
      "    \"label\": \"speech\",\n",
      "    \"end\": 420,\n",
      "    \"begin\": 410\n",
      "}\n",
      "{\n",
      "    \"label\": \"music\",\n",
      "    \"end\": 450,\n",
      "    \"begin\": 420\n",
      "}\n",
      "{\n",
      "    \"label\": \"speech\",\n",
      "    \"end\": 460,\n",
      "    \"begin\": 450\n",
      "}\n",
      "{\n",
      "    \"label\": \"music\",\n",
      "    \"end\": 480,\n",
      "    \"begin\": 460\n",
      "}\n",
      "{\n",
      "    \"label\": \"speech\",\n",
      "    \"end\": 490,\n",
      "    \"begin\": 480\n",
      "}\n",
      "{\n",
      "    \"label\": \"music\",\n",
      "    \"end\": 520,\n",
      "    \"begin\": 490\n",
      "}\n",
      "{\n",
      "    \"label\": \"noise\",\n",
      "    \"end\": 560,\n",
      "    \"begin\": 520\n",
      "}\n",
      "{\n",
      "    \"label\": \"music\",\n",
      "    \"end\": 570,\n",
      "    \"begin\": 560\n",
      "}\n",
      "{\n",
      "    \"label\": \"speech\",\n",
      "    \"end\": 580,\n",
      "    \"begin\": 570\n",
      "}\n",
      "{\n",
      "    \"label\": \"silence\",\n",
      "    \"end\": 590,\n",
      "    \"begin\": 580\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(len(my_dict))\n",
    "final_dict={}\n",
    "objects=0\n",
    "curr_dict={}\n",
    "curr_dict=my_dict[objects]\n",
    "final_dict_count=0\n",
    "for objects in range (len(my_dict)):\n",
    "    if curr_dict['label']==my_dict[objects]['label']:\n",
    "        \n",
    "        continue\n",
    "        \n",
    "    else:\n",
    "        #print('executing_else')\n",
    "        curr_dict['end']=my_dict[objects-1]['end']\n",
    "        final_dict.update(curr_dict)\n",
    "        curr_dict.update(my_dict[objects])\n",
    "        #print((final_dict))\n",
    "        #print('curr_dict',objects,curr_dict)\n",
    "        json_data=json.dumps(final_dict,indent=4)\n",
    "        json_string+=str(json_data)\n",
    "        print(json_data)\n",
    "        \n",
    "\n",
    "\n",
    "    #print(my_dict[objects])\n",
    "#with open('data.txt', 'a') as outfile:\n",
    "        #json.dump(argument_filename+'::'+json_string, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"label\": \"silence\",\n",
      "    \"end\": 20,\n",
      "    \"begin\": 0\n",
      "}{\n",
      "    \"label\": \"speech\",\n",
      "    \"end\": 50,\n",
      "    \"begin\": 20\n",
      "}{\n",
      "    \"label\": \"music\",\n",
      "    \"end\": 110,\n",
      "    \"begin\": 50\n",
      "}{\n",
      "    \"label\": \"speech\",\n",
      "    \"end\": 120,\n",
      "    \"begin\": 110\n",
      "}{\n",
      "    \"label\": \"silence\",\n",
      "    \"end\": 130,\n",
      "    \"begin\": 120\n",
      "}{\n",
      "    \"label\": \"speech\",\n",
      "    \"end\": 150,\n",
      "    \"begin\": 130\n",
      "}{\n",
      "    \"label\": \"music\",\n",
      "    \"end\": 170,\n",
      "    \"begin\": 150\n",
      "}{\n",
      "    \"label\": \"noise\",\n",
      "    \"end\": 190,\n",
      "    \"begin\": 170\n",
      "}{\n",
      "    \"label\": \"music\",\n",
      "    \"end\": 220,\n",
      "    \"begin\": 190\n",
      "}{\n",
      "    \"label\": \"noise\",\n",
      "    \"end\": 230,\n",
      "    \"begin\": 220\n",
      "}{\n",
      "    \"label\": \"music\",\n",
      "    \"end\": 250,\n",
      "    \"begin\": 230\n",
      "}{\n",
      "    \"label\": \"speech\",\n",
      "    \"end\": 290,\n",
      "    \"begin\": 250\n",
      "}{\n",
      "    \"label\": \"music\",\n",
      "    \"end\": 300,\n",
      "    \"begin\": 290\n",
      "}{\n",
      "    \"label\": \"speech\",\n",
      "    \"end\": 310,\n",
      "    \"begin\": 300\n",
      "}{\n",
      "    \"label\": \"noise\",\n",
      "    \"end\": 320,\n",
      "    \"begin\": 310\n",
      "}{\n",
      "    \"label\": \"speech\",\n",
      "    \"end\": 330,\n",
      "    \"begin\": 320\n",
      "}{\n",
      "    \"label\": \"music\",\n",
      "    \"end\": 340,\n",
      "    \"begin\": 330\n",
      "}{\n",
      "    \"label\": \"speech\",\n",
      "    \"end\": 350,\n",
      "    \"begin\": 340\n",
      "}{\n",
      "    \"label\": \"noise\",\n",
      "    \"end\": 360,\n",
      "    \"begin\": 350\n",
      "}{\n",
      "    \"label\": \"music\",\n",
      "    \"end\": 380,\n",
      "    \"begin\": 360\n",
      "}{\n",
      "    \"label\": \"noise\",\n",
      "    \"end\": 390,\n",
      "    \"begin\": 380\n",
      "}{\n",
      "    \"label\": \"music\",\n",
      "    \"end\": 410,\n",
      "    \"begin\": 390\n",
      "}{\n",
      "    \"label\": \"speech\",\n",
      "    \"end\": 420,\n",
      "    \"begin\": 410\n",
      "}{\n",
      "    \"label\": \"music\",\n",
      "    \"end\": 450,\n",
      "    \"begin\": 420\n",
      "}{\n",
      "    \"label\": \"speech\",\n",
      "    \"end\": 460,\n",
      "    \"begin\": 450\n",
      "}{\n",
      "    \"label\": \"music\",\n",
      "    \"end\": 480,\n",
      "    \"begin\": 460\n",
      "}{\n",
      "    \"label\": \"speech\",\n",
      "    \"end\": 490,\n",
      "    \"begin\": 480\n",
      "}{\n",
      "    \"label\": \"music\",\n",
      "    \"end\": 520,\n",
      "    \"begin\": 490\n",
      "}{\n",
      "    \"label\": \"noise\",\n",
      "    \"end\": 560,\n",
      "    \"begin\": 520\n",
      "}{\n",
      "    \"label\": \"music\",\n",
      "    \"end\": 570,\n",
      "    \"begin\": 560\n",
      "}{\n",
      "    \"label\": \"speech\",\n",
      "    \"end\": 580,\n",
      "    \"begin\": 570\n",
      "}{\n",
      "    \"label\": \"silence\",\n",
      "    \"end\": 590,\n",
      "    \"begin\": 580\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json_string)\n",
    "del (json_string,curr_dict,my_dict,final_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_files()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
